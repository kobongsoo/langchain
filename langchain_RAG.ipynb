{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90896ad8-2f9e-49ad-93de-edd15978d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예제 : https://teddylee777.github.io/langchain/rag-tutorial/\n",
    "#\n",
    "# LangChain 설치 및 업데이트\n",
    "!pip install -U langchain langchain-community langchain-experimental langchain-core langchain-openai langsmith langchainhub python-dotenv unstructured chromadb faiss-cpu rank_bm25 python-docx sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc6765a-ccf7-45bc-8e82-5d9cf07bbb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma, FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# 루트경로에 .env 파일을 만들고, OPENAI_API_KEY='{API_KEY}' 식으로 입력한다.\n",
    "# API 키를 환경변수로 관리하기 위한 .env설정 파일 로딩\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # API 키 정보 로드\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f634a3e-8f7b-4ed7-a44f-8123cbc49f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:03<00:00,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 9\n",
      "\n",
      "[페이지내용]\n",
      "대학교 학자금대출 제도\n",
      "\n",
      "목적 : 대학생 자녀를 가진 임직원의 학자금을 대출함으로써 임직원의 복지향상, 근로의욕의 제고 및 장기근속 유도\n",
      "\n",
      "도입기준\n",
      "\n",
      "대학생 자녀를 가진 정규직 임직원\n",
      "\n",
      "지급신청 : 부문장(본부는 본부장) 전결로 그룹웨어를 통해 신청\n",
      "\n",
      "대학교 학자금대출 신청서(그룹웨어)\n",
      "\n",
      "재학증명서, 입학증명서 중 1종 첨부\n",
      "\n",
      "지원절차\n",
      "\n",
      "그룹웨어를 통해 ‘\n",
      "\n",
      "[metadata]\n",
      "{'source': 'doc_test/06.대학교 학자금 대출 지원 제도_20.02.01.txt'}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 단계1: 폴더내 모든 문서 로딩\n",
    "#!pip install unstructured\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "loader = DirectoryLoader(\".\", glob=\"./doc_test/*.txt\", show_progress=True)\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "\n",
    "# 10번째 페이지의 내용 출력\n",
    "print(f\"\\n[페이지내용]\\n{docs[1].page_content[:200]}\")\n",
    "print(f\"\\n[metadata]\\n{docs[1].metadata}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9452f2f-cb1d-4187-8069-cf418a8bcd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*chunk 수:40\n",
      "\n",
      "*splits[0]:\n",
      "page_content='경조사 지원 규정\\n\\n1. 적용대상\\n\\n계약직 사원을 포함한 임직원(고문 및 용역은 사장이 별도로 결정)\\n\\n2. 경조사 지원기준\\n\\n구 분\\n\\n내 역\\n\\n휴가(일)\\n\\n금액(원)\\n\\n기타\\n\\n경 사\\n\\n본인 결혼\\n\\n자녀 결혼\\n\\n형제자매결혼\\n\\n자녀 출산(배우자)\\n\\n부모 회갑\\n\\n배우자 부모회갑\\n\\n부모고희(칠순)\\n\\n배우자부모고희\\n\\n5\\n\\n1\\n\\n1\\n\\n10\\n\\n1\\n\\n1\\n\\n1\\n\\n1\\n\\n500,000\\n\\n300,000\\n\\n100,000\\n\\n100,000\\n\\n200,000\\n\\n200,000\\n\\n300,000\\n\\n300,000\\n\\n화환 지급\\n\\n화환 지급\\n\\n1회 분할 사용 가능\\n\\n조 사\\n\\n본인 사망\\n\\n배우자 사망\\n\\n부모 사망\\n\\n자녀 사망\\n\\n배우자 부모 사망\\n\\n형제자매 사망\\n\\n조부모/외조부모 사망\\n\\n5\\n\\n5\\n\\n5\\n\\n5\\n\\n3\\n\\n3\\n\\n1,000,000\\n\\n1,000,000\\n\\n1,000,000\\n\\n1,000,000 500,000\\n\\n300,000\\n\\n200,000\\n\\n조화 지급\\n\\n조화 지급\\n\\n조화 지급\\n\\n조화 지급\\n\\n조화 지급\\n\\n조화 지급' metadata={'source': 'doc_test/03.경조사지원규정_12.01.01.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "\n",
    "# 단계 2: 문서 분할(Split Documents)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f'*chunk 수:{len(splits)}\\n')\n",
    "print(f'*splits[0]:\\n{splits[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37295c15-d252-4f36-8db7-6ccef28ba5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'조화 지급\\n\\n조화 지급\\n\\n조화 지급\\n\\n조화 지급\\n\\n조화 지급\\n\\n조화 지급\\n\\n3. 신청서류\\n\\n경조금 : 경조금지급신청서 및 증빙서류 1부\\n\\n휴 가: 휴가원 1부\\n\\n4. 경조휴가일수\\n\\n공휴일과 경조사가 중복되었을 경우 휴가일수는 공휴일을 제외하여 계산한다.\\n\\n5. 결혼퇴직\\n\\n결혼퇴직의 경우 퇴직 1개월 이내에 결혼할 시에는 위의 기준에 의거하여 지급한다.\\n\\n6. 기타\\n\\n경조금 신청 시 휴가 신청도 같이 진행해야 함이 원칙임\\n\\n특별한 경우 사업부장 합의 시 경조금 신청일 이후 신청 가능(6개월 이내)\\n\\n분할 사용 불가, 발생일 이전 신청 불가.\\n\\n부 칙\\n\\n(시행일) 이 규정은 2007년 9월 14일부터 시행한다.\\n\\n(개정일) 이 규정은 2012년 1월 1일부터 개정 시행한다.\\n\\n경조사지원규정 1/1'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a08570dc-11f9-4e12-babe-220d93f3ace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 105, which is longer than the specified 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경조사 지원 규정\n",
      "1. 적용대상\n",
      "계약직 사원을 포함한 임직원(고문 및 용역은 사장이 별도로 결정)\n",
      "2. 경조사 지원기준\n",
      "구 분\n",
      "내 역\n",
      "휴가(일)\n",
      "금액(원)\n",
      "기타\n",
      "경 사\n",
      "본인\n",
      "--------------------\n",
      "사\n",
      "본인 결혼\n",
      "자녀 결혼\n",
      "형제자매결혼\n",
      "자녀 출산(배우자)\n",
      "부모 회갑\n",
      "배우자\n",
      "--------------------\n",
      "부모회갑\n",
      "부모고희(칠순)\n",
      "배우자부모고희\n",
      "5\n",
      "1\n",
      "1\n",
      "10\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "500,000\n",
      "300,000\n",
      "100,000\n",
      "100,000\n",
      "200,000\n",
      "200,000\n",
      "300,000\n",
      "300,000\n",
      "화환\n",
      "--------------------\n",
      "지급\n",
      "화환 지급\n",
      "1회 분할 사용 가능\n",
      "조 사\n",
      "본인 사망\n",
      "배우자 사망\n",
      "부모 사망\n",
      "자녀 사망\n",
      "배우자 부모 사망\n",
      "형제자매 사망\n",
      "조부모/외조부모\n",
      "--------------------\n",
      "사망\n",
      "-\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "1,000,000\n",
      "1,000,000\n",
      "1,000,000\n",
      "1,000,000 500,000\n",
      "300,000\n",
      "200,000\n",
      "조화 지급\n",
      "조화 지급\n",
      "조화\n",
      "--------------------\n",
      "지급\n",
      "조화 지급\n",
      "조화 지급\n",
      "조화 지급\n",
      "조화 지급\n",
      "3. 신청서류\n",
      "경조금 : 경조금지급신청서 및 증빙서류 1부\n",
      "휴 가: 휴가원 1부\n",
      "4. 경조휴가일수\n",
      "공휴일과 경조사가 중\n",
      "--------------------\n",
      "============================================================\n",
      "경조사 지원 규정\n",
      "1. 적용대상\n",
      "계약직 사원을 포함한 임직원(고문 및 용역은 사장이 별도로 결정)\n",
      "2. 경조사 지원기준\n",
      "구 분\n",
      "내 역\n",
      "휴가(일)\n",
      "금액(원)\n",
      "기타\n",
      "경 사\n",
      "본인 결혼\n",
      "--------------------\n",
      "경 사\n",
      "본인 결혼\n",
      "자녀 결혼\n",
      "형제자매결혼\n",
      "자녀 출산(배우자)\n",
      "부모 회갑\n",
      "배우자 부모회갑\n",
      "부모고희(칠순)\n",
      "배우자부모고희\n",
      "5\n",
      "1\n",
      "1\n",
      "10\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "500,000\n",
      "300,000\n",
      "--------------------\n",
      "300,000\n",
      "100,000\n",
      "100,000\n",
      "200,000\n",
      "200,000\n",
      "300,000\n",
      "300,000\n",
      "화환 지급\n",
      "화환 지급\n",
      "1회 분할 사용 가능\n",
      "조 사\n",
      "본인 사망\n",
      "배우자 사망\n",
      "--------------------\n",
      "배우자 사망\n",
      "부모 사망\n",
      "자녀 사망\n",
      "배우자 부모 사망\n",
      "형제자매 사망\n",
      "조부모/외조부모 사망\n",
      "-\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "1,000,000\n",
      "1,000,000\n",
      "1,000,000\n",
      "--------------------\n",
      "1,000,000\n",
      "1,000,000 500,000\n",
      "300,000\n",
      "200,000\n",
      "조화 지급\n",
      "조화 지급\n",
      "조화 지급\n",
      "조화 지급\n",
      "조화 지급\n",
      "조화 지급\n",
      "3. 신청서류\n",
      "--------------------\n",
      "3. 신청서류\n",
      "경조금 : 경조금지급신청서 및 증빙서류 1부\n",
      "휴 가: 휴가원 1부\n",
      "4. 경조휴가일수\n",
      "공휴일과 경조사가 중\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# character_text_splitter 와 RecursiveCharacterTextSplitter 비교\n",
    "# => 같은 문서를 불러와서 100개로 split 할때 출력을 보여줌. RecursiveCharacterTextSplitter가 더 좋음.\n",
    "# => RecursiveCharacterTextSplitter가 의미적으로 가장 연관성이 강한 텍스트 조각인 것처럼 보이는 \n",
    "# 모든 단락(그리고 문장, 단어)을 가능한 한 길게 유지하려는 효과가 있다.\n",
    "with open(\"./doc_test/03.경조사지원규정_12.01.01.txt\", \"r\") as f:\n",
    "    text = f.read()[:500]\n",
    "    \n",
    "character_text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=10, separator=\" \"\n",
    ")\n",
    "for sent in character_text_splitter.split_text(text):\n",
    "    print(sent)\n",
    "    print(\"--\"*10)\n",
    "    \n",
    "\n",
    "print(\"===\" * 20)\n",
    "\n",
    "recursive_text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100, chunk_overlap=10\n",
    ")\n",
    "for sent in recursive_text_splitter.split_text(text):\n",
    "    print(sent)\n",
    "    print(\"--\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f5f06c-e5dd-49d3-a8b2-123f1c89bf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# openai 임베딩 모델 이용\n",
    "#semantic_text_splitter = SemanticChunker(\n",
    "#    OpenAIEmbeddings, add_start_index=True)\n",
    "\n",
    "# bge 임베딩 모델 이용 => bge는 영문에 특화되어 있어서 영문문서일때는 좋음.\n",
    "#semantic_text_splitter = SemanticChunker(\n",
    "#    HuggingFaceBgeEmbeddings, add_start_index=True)\n",
    "\n",
    "# hugggingface에 다른 모델 이용\n",
    "#model_name = \"BAAI/bge-small-en\"\n",
    "model_name = \"bongsoo/kpf-sbert-v1\"\n",
    "#model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "custom_embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    #model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# SemanticChunker 를 생성합니다.\n",
    "semantic_text_splitter = SemanticChunker(\n",
    "    custom_embedding_model, add_start_index=True)\n",
    "\n",
    "# chain of density 논문의 일부 내용을 불러옵니다\n",
    "with open(\"./doc_test/25.출장여비규정_16.04.01.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "for sent in semantic_text_splitter.split_text(text):\n",
    "    print(sent)\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf302d5-5dda-4cee-af88-3a395443fbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sqlalchemy 에러가 나면 업그레이드 해준다.\n",
    "#!pip install --upgrade sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fed69f7e-a4d8-4bf4-b430-b9744a02e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단계 3: 임베딩\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "from langchain_community.vectorstores import FAISS, Chroma\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 단계 3, 4: 임베딩 & 벡터스토어 생성(Create Vectorstore)\n",
    "# 벡터스토어를 생성합니다.\n",
    "#vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "\n",
    "#vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "\n",
    "# 단계 5: 리트리버 생성(Create Retriever)\n",
    "# 사용자의 질문(query) 에 부합하는 문서를 검색합니다.\n",
    "# 유사도 높은 K 개의 문서를 검색합니다.\n",
    "k = 3\n",
    "\n",
    "# BM25 retriver 생성\n",
    "# (Sparse) bm25 retriever and (Dense) faiss retriever 를 초기화 합니다.\n",
    "bm25_retriever = BM25Retriever.from_documents(splits)\n",
    "bm25_retriever.k = k\n",
    "\n",
    "# 임베딩 retiver 모델을 불러옴.\n",
    "model_name = \"bongsoo/kpf-sbert-v1\"\n",
    "#model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "custom_embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    #model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n",
    "\n",
    "# 임베딩 retriver 생성\n",
    "#faiss_vectorstore = FAISS.from_documents(documents=splits, embedding=OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "faiss_vectorstore = FAISS.from_documents(documents=splits, embedding=custom_embedding_model)\n",
    "faiss_retriever = faiss_vectorstore.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "# bm25 + 임베딩 retriver 합쳐서 만듬.\n",
    "# initialize the ensemble retriever\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, faiss_retriever], weights=[0.5, 0.5]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d46aebd9-6e81-4c2d-9779-51db9dbedf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG-prompt:\n",
      "input_variables=['context', 'question'] metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'} messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))]\n"
     ]
    }
   ],
   "source": [
    "# 단계 6: 프롬프트 생성(Create Prompt)\n",
    "# 프롬프트를 생성합니다.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "print(f'RAG-prompt:\\n{prompt}')\n",
    "\n",
    "# 단계 7: 언어모델 생성(Create LLM)\n",
    "# 모델(LLM) 을 생성합니다.\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    # 검색한 문서 결과를 하나의 문단으로 합쳐줍니다.\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24196cf0-0447-4ca7-a0a8-e22944660568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 9\n",
      "============================================================\n",
      "[HUMAN]\n",
      "1박2일 서울 출장시 식비는 얼마인가요?\n",
      "\n",
      "[AI]\n",
      "서울 출장시 식비는 1일당 20,000원입니다. 식비는 실비로 정산 가능하며, 상한액은 서울특별시 70,000원입니다.\n"
     ]
    }
   ],
   "source": [
    "# 단계 8: 체인 생성(Create Chain)\n",
    "rag_chain = (\n",
    "    {\"context\": ensemble_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 단계 8: 체인 실행(Run Chain)\n",
    "# 문서에 대한 질의를 입력하고, 답변을 출력합니다.\n",
    "question = \"1박2일 서울 출장시 식비는 얼마인가요?\"\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"문서의 수: {len(docs)}\")\n",
    "print(\"===\" * 20)\n",
    "print(f\"[HUMAN]\\n{question}\\n\")\n",
    "print(f\"[AI]\\n{response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2998c3-6718-4fb2-a4f2-f17d747e2ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFaceHub 객체 생성\n",
    "# 모델들은 아래 사이트 참조\n",
    "# https://huggingface.co/spaces/upstage/open-ko-llm-leaderboard\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "#repo_id = \"google/flan-t5-xxl\"\n",
    "repo_id = \"hwkwon/S-SOLAR-10.7B-v1.5\"\n",
    "\n",
    "llm_model = HuggingFaceHub(\n",
    "    repo_id=repo_id, model_kwargs={\"temperature\": 0.1, \"max_length\": 512}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d0ba98-3f6c-423b-9901-9ec8b610e598",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model.invoke(\"한국의 수도는 어디인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a655196-26cb-4e2c-a0ac-edb1aa3eb756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://teddylee777.github.io/langchain/langchain-tutorial-02/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecce5b3-63e9-42a3-9136-8bacb8c635ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 직접 다운로드 후 로컬(local)에서 추론Permalink\n",
    "#이전 방식은 허깅페이스 서버에서 선택된 모델로 추론하고, 이에 대한 답변을 반환받는 방식입니다.\n",
    "#추론 방식이 간편하지만, 서버의 성능에 따라 다르지만 추론 속도가 대체적으로 오래 걸리는 편입니다. \n",
    "#따라서, 결과를 받는데 시간이 오래 걸리거나, 혹은 답변의 지연시간이 긴 경우, Timeout 에러가 발생할 수 있습니다\n",
    "#만약, 좋은 성능의 GPU 를 탑재한 서버가 있다면, 로컬에 모델을 직접 다운로드 받아 GPU 부스트를 받아서 추론할 수 있습니다. 아래는 예시코드 입니다.\n",
    "\n",
    "import os\n",
    "# 허깅페이스 모델/토크나이저를 다운로드 받을 경로\n",
    "# (예시)\n",
    "# os.environ['HF_HOME'] = '/home/jovyan/work/tmp'\n",
    "os.environ['HF_HOME'] = './model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff47672-ac32-454f-9e0a-263cc5b92e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "# HuggingFace Model ID\n",
    "model_id = 'beomi/llama-2-ko-7b'\n",
    "#gwonny/nox-solar-10.7b-v4-kolon-all-5-v2.0 \n",
    "\n",
    "# HuggingFacePipeline 객체 생성\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_id, \n",
    "    device=0,               # -1: CPU(default), 0번 부터는 CUDA 디바이스 번호 지정시 GPU 사용하여 추론\n",
    "    task=\"text-generation\", # 텍스트 생성\n",
    "    model_kwargs={\"temperature\": 0.1, \n",
    "                  \"max_length\": 512},\n",
    ")\n",
    "\n",
    "# 템플릿\n",
    "template = \"\"\"질문: {question}\n",
    "\n",
    "답변: \"\"\"\n",
    "\n",
    "# 프롬프트 템플릿 생성\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# LLM Chain 객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b33acd4-ce94-4aeb-a729-a2620663b2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e0530-c86a-4ae2-8473-9059b45b200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02b6c5-c89e-437b-8f2f-e336e54cc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 루트경로에 .env 파일을 만들고, OPENAI_API_KEY='{API_KEY}' 식으로 입력한다.\n",
    "# API 키를 환경변수로 관리하기 위한 .env설정 파일 로딩\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # API 키 정보 로드\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25fb88e4-ad84-4775-9981-2e0d28729c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*벡터길이:3072\n",
      "[-0.0029831711300205687, -0.008144287037685861, -0.012891286422468696, 0.030138463331549372, 0.01702478081324163]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# OpenAI의 \"text-embedding-3-large\" 모델을 사용하여 임베딩을 생성합니다.\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "text = (\"임베딩 테스트를 하기 위한 샘플 문장입니다.\")  # 테스트용 문서 텍스트를 정의합니다.\n",
    "\n",
    "# 임베딩\n",
    "query_result = embeddings.embed_query(text)\n",
    "\n",
    "print(f'*벡터길이:{len(query_result)}')\n",
    "print(query_result[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da25ca18-4a53-4338-ba7c-bb94eeab0c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*doc 벡터 수:5\n",
      "*1번째 doc 벡터: [-0.03816284589388166, -0.026379329928663993, -0.010243785507366298, 0.02217494683343758, 0.0025504003128992646, -0.0021514058917956073, 0.0016161908766246223, 0.018800193333382474, 0.01566448425979391, -0.00607455751081853]\n",
      "*3번째 doc 벡터: [-0.019650334975989246, -0.04274467111535306, -0.003007392938696787, 0.008182550981876334, 0.018722165836765926, -0.012469231457955761, -0.0354170137420483, 0.01618191080881683, -0.0002950145644571675, -0.02911522683638425]\n"
     ]
    }
   ],
   "source": [
    "# 도큐먼트 임베딩\n",
    "\n",
    "# embeddings.embed_documents() 함수를 사용하여 텍스트 문서를 임베딩합니다.\n",
    "# text를 리스트 형태로 만들고, 임베딩 함수에 전달합니다.\n",
    "# 함수 호출 결과로 반환된 임베딩 벡터를 doc_result 변수에 할당합니다.\n",
    "\n",
    "text = [\"안녕하세요\", \"날씨가 좋네요\", \"화창한 날씨 입니다.\", \"운동장에서 축구하고 있어요.\", \"반갑습니다.\"]\n",
    "doc_result = embeddings.embed_documents(text)\n",
    "\n",
    "print(f'*doc 벡터 수:{len(doc_result)}')\n",
    "\n",
    "print(f'*1번째 doc 벡터: {doc_result[0][:10]}')\n",
    "print(f'*3번째 doc 벡터: {doc_result[2][:10]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfd73c91-2279-4e91-a9fc-44e3515580ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 차원 지정\n",
    "# dimensions=1024를 전달함으로써 임베딩의 크기를 1024로 줄일 수 있습니다.\n",
    "# 원래 text-embedding-3-large 모델이 차원은 3072 임.\n",
    "text = \"안녕하세요\"\n",
    "\n",
    "embeddings_1024 = OpenAIEmbeddings(model=\"text-embedding-3-large\", dimensions=1024)\n",
    "\n",
    "# 주어진 텍스트를 임베딩하고 첫 번째 임베딩 벡터의 길이를 반환합니다.\n",
    "# => text가 리스트가 아니므로 [] 붙여서 리스트 형태로 입력한다.\n",
    "len(embeddings_1024.embed_documents([text])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "757802c3-8180-4bef-9040-d6cfd46e0358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[유사도 0.9652] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 반갑습니다!\n",
      "[유사도 0.8575] 안녕하세요? 반갑습니다. \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
      "[유사도 0.5451] 안녕하세요? 반갑습니다. \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1725] 안녕하세요? 반갑습니다. \t <=====> \t I like to eat apples.\n",
      "[유사도 0.8402] 안녕하세요? 반갑습니다! \t <=====> \t 안녕하세요? 만나서 반가워요.\n",
      "[유사도 0.5340] 안녕하세요? 반갑습니다! \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1857] 안녕하세요? 반갑습니다! \t <=====> \t I like to eat apples.\n",
      "[유사도 0.5856] 안녕하세요? 만나서 반가워요. \t <=====> \t Hi, nice to meet you.\n",
      "[유사도 0.1576] 안녕하세요? 만나서 반가워요. \t <=====> \t I like to eat apples.\n",
      "[유사도 0.2474] Hi, nice to meet you. \t <=====> \t I like to eat apples.\n"
     ]
    }
   ],
   "source": [
    "# 유사도 계산\n",
    "# => 여기서는 cosine_similarity 로 유사도 계산 함.\n",
    "\n",
    "sentence1 = \"안녕하세요? 반갑습니다.\"\n",
    "sentence2 = \"안녕하세요? 반갑습니다!\"\n",
    "sentence3 = \"안녕하세요? 만나서 반가워요.\"\n",
    "sentence4 = \"Hi, nice to meet you.\"\n",
    "sentence5 = \"I like to eat apples.\"\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sentences = [sentence1, sentence2, sentence3, sentence4, sentence5]\n",
    "embedded_sentences = embeddings_1024.embed_documents(sentences)\n",
    "\n",
    "def similarity(a, b):\n",
    "    return cosine_similarity([a], [b])[0][0]\n",
    "\n",
    "for i, sentence in enumerate(embedded_sentences):\n",
    "    for j, other_sentence in enumerate(embedded_sentences):\n",
    "        if i < j:\n",
    "            print(\n",
    "                f\"[유사도 {similarity(sentence, other_sentence):.4f}] {sentences[i]} \\t <=====> \\t {sentences[j]}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa33630-dc9a-409e-bf3c-023d01d3e9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

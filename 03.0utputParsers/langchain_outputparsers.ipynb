{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab08036-1d23-4868-8e41-a1fcc9b3c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출처 : https://wikidocs.net/233344\n",
    "# LangChain 설치 및 업데이트\n",
    "#!pip install -U langchain langchain-community langchain-experimental langchain-core langchain-openai langsmith langchainhub python-dotenv unstructured chromadb faiss-cpu rank_bm25 python-docx sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81db76-8a6c-4b58-b504-bbd93c861e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 루트경로에 .env 파일을 만들고, OPENAI_API_KEY='{API_KEY}' 식으로 입력한다.\n",
    "# API 키를 환경변수로 관리하기 위한 .env설정 파일 로딩\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # API 키 정보 로드\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7222ac23-b2ff-4a27-bc5e-fa2ba3816952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmailSummary(person='김철수', email='chulsoo.kim@bikecorporation.me', subject='\"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안', summary='바이크코퍼레이션의 김철수 상무가 이은채 대리님에게 ZENESIS 모델에 대한 상세한 정보를 요청하고, 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안함', date='2023-01-15 10:00 AM')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pydantic 출력 파서 \n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "# model 정의\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# email 본문 정의\n",
    "email_conversation = \"\"\"From: 김철수 (chulsoo.kim@bikecorporation.me)\n",
    "To: 이은채 (eunchae@teddyinternational.me)\n",
    "Subject: \"ZENESIS\" 자전거 유통 협력 및 미팅 일정 제안\n",
    "\n",
    "안녕하세요, 이은채 대리님,\n",
    "\n",
    "저는 바이크코퍼레이션의 김철수 상무입니다. 최근 보도자료를 통해 귀사의 신규 자전거 \"ZENESIS\"에 대해 알게 되었습니다. 바이크코퍼레이션은 자전거 제조 및 유통 분야에서 혁신과 품질을 선도하는 기업으로, 이 분야에서의 장기적인 경험과 전문성을 가지고 있습니다.\n",
    "\n",
    "ZENESIS 모델에 대한 상세한 브로슈어를 요청드립니다. 특히 기술 사양, 배터리 성능, 그리고 디자인 측면에 대한 정보가 필요합니다. 이를 통해 저희가 제안할 유통 전략과 마케팅 계획을 보다 구체화할 수 있을 것입니다.\n",
    "\n",
    "또한, 협력 가능성을 더 깊이 논의하기 위해 다음 주 화요일(1월 15일) 오전 10시에 미팅을 제안합니다. 귀사 사무실에서 만나 이야기를 나눌 수 있을까요?\n",
    "\n",
    "감사합니다.\n",
    "\n",
    "김철수\n",
    "상무이사\n",
    "바이크코퍼레이션\n",
    "\"\"\"\n",
    "\n",
    "# email 본문을 파싱할 구조 설정\n",
    "class EmailSummary(BaseModel):\n",
    "    person: str = Field(description=\"메일을 보낸 사람\")\n",
    "    email: str = Field(description=\"메일을 보낸 사람의 이메일 주소\")\n",
    "    subject: str = Field(description=\"메일 제목\")\n",
    "    summary: str = Field(description=\"메일 본문을 요약한 텍스트\")\n",
    "    date: str = Field(description=\"메일 본문에 언급된 미팅 날짜와 시간\")\n",
    "\n",
    "\n",
    "# PydanticOutputParser 생성\n",
    "parser = PydanticOutputParser(pydantic_object=EmailSummary)\n",
    "\n",
    "# prompt 생성\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a helpful assistant. Please answer the following questions in KOREAN.\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "EMAIL CONVERSATION:\n",
    "{email_conversation}\n",
    "\n",
    "FORMAT:\n",
    "{format}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# format 에 PydanticOutputParser의 format을 추가\n",
    "prompt = prompt.partial(format=parser.get_format_instructions())\n",
    "\n",
    "\n",
    "# 체인 구성\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# chain 을 실행하고 결과를 출력합니다.\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"email_conversation\": email_conversation,\n",
    "        \"question\": \"이메일 내용중 주요 내용을 추출해 주세요.\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# 결과는 EmailSummary 객체 형태로 출력됩니다.\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1c15990-8df0-4eb0-863d-308ca12b1a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['경복궁', '인사동', '남산타워', '부산 해운대해수욕장', '제주도']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 콤마 구분자 파서\n",
    "# CommaSeparatedListOutputParser\n",
    "# CommaSeparatedListOutputParser 는 쉼표로 구분된 항목 목록을 반환할 필요가 있을 때 유용합니다.\n",
    "# 이 출력 파서를 사용하면, 사용자가 입력한 데이터나 요청한 정보를 쉼표로 구분하여 명확하고 간결한 목록 형태로 \n",
    "# 제공받을 수 있습니다.\n",
    "\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 콤마로 구분된 리스트 출력 파서 초기화\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 출력 형식 지침 가져오기\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = PromptTemplate(\n",
    "    # 주제에 대한 다섯 가지를 나열하라는 템플릿\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],  # 입력 변수로 'subject' 사용\n",
    "    # 부분 변수로 형식 지침 사용\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "# ChatOpenAI 모델 초기화\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# 프롬프트, 모델, 출력 파서를 연결하여 체인 생성\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# 체인 실행\n",
    "chain.invoke(\n",
    "    {\"subject\": \"대한민국 관광명소\"}\n",
    ")  # \"대한민국 관광명소\"에 대한 체인 호출 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dee78121-e218-4a14-b501-e889fa298b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '서울', 'source': 'https://ko.wikipedia.org/wiki/%EC%84%9C%EC%9A%B8'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 구조화된 출력 파서\n",
    "# StructuredOutputParser\n",
    "# 이 출력 파서는 여러 필드를 반환하고자 할 때 사용할 수 있습니다. Pydantic/JSON 파서가 더 강력하지만, \n",
    "# 이는 덜 강력한 모델에 유용합니다.\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ResponseSchema 클래스를 사용하여 사용자의 질문에 대한 답변과 사용된 소스(웹사이트)에 대한 설명을 포함하는 응답 스키마를 정의합니다.\n",
    "# StructuredOutputParser를 response_schemas를 사용하여 초기화하여, 정의된 응답 스키마에 따라 출력을 구조화합니다.\n",
    "\n",
    "# 사용자의 질문에 대한 답변\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"사용자의 질문에 대한 답변\"),\n",
    "    ResponseSchema(\n",
    "        name=\"source\",\n",
    "        description=\"사용자의 질문에 답하기 위해 사용된 출처, 웹사이트 이여야 합니다.\",\n",
    "    ),\n",
    "]\n",
    "# 응답 스키마를 기반으로 한 구조화된 출력 파서 초기화\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# output_parser.get_format_instructions() 함수를 호출하여 포맷 지시사항을 가져옵니다.\n",
    "# PromptTemplate 클래스를 사용하여 사용자의 질문에 최대한 답변하는 프롬프트 템플릿을 생성합니다.\n",
    "# 템플릿에는 question이라는 입력 변수와 format_instructions라는 부분 변수가 포함됩니다.\n",
    "\n",
    "# 출력 형식 지시사항을 파싱합니다.\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "    # 사용자의 질문에 최대한 답변하도록 템플릿을 설정합니다.\n",
    "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
    "    # 입력 변수로 'question'을 사용합니다.\n",
    "    input_variables=[\"question\"],\n",
    "    # 부분 변수로 'format_instructions'을 사용합니다.\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0)  # ChatOpenAI 모델 초기화\n",
    "chain = prompt | model | output_parser  # 프롬프트, 모델, 출력 파서를 연결\n",
    "\n",
    "chain.invoke({\"question\": \"대한민국의 수도는 어디인가요?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4eec8ce-ba6f-4550-b725-2fe50c051f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': '온난화는 지구 온도가 상승하는 현상을 의미하며, 이는 대기 중 온실가스 농도 증가와 인간 활동에 의해 발생합니다. 이로 인해 극지방의 빙하가 녹아 해수면 상승, 기후 변화 등의 문제가 발생할 수 있습니다.',\n",
       " 'hashtags': '#온난화 #기후변화 #온실가스'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# JsonOutputParser\n",
    "# json 형태로 출력하는 파서\n",
    "# 이 출력 파서는 사용자가 원하는 JSON 스키마를 지정할 수 있게 해주며, 그 스키마에 맞게 LLM에서 데이터를 조회하여 결과를 도출해줍니다.\n",
    "# LLM이 데이터를 정확하고 효율적으로 처리하여 원하는 형태의 JSON을 생성하기 위해서는, \n",
    "# 모델의 용량이 충분해야 한다는 점을 기억해야 합니다.\n",
    "# 데이터 모델을 정의할 때는 Pydantic과 같은 도구를 사용하여, 스키마가 잘 정의되고 검증될 수 있도록 할 수 있습니다.\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0)  # ChatOpenAI 모델 초기화 및 온도 설정\n",
    "\n",
    "# 원하는 데이터 구조를 정의합니다.\n",
    "class Topic(BaseModel):\n",
    "    description: str = Field(description=\"Concise description about topic\")\n",
    "    hashtags: str = Field(description=\"Some keywords in hashtag format\")\n",
    "    \n",
    "# 질의 작성\n",
    "query = \"온난화에 대해 알려주세요.\"\n",
    "\n",
    "# 파서를 설정하고 프롬프트 템플릿에 지시사항을 주입합니다.\n",
    "parser = JsonOutputParser(pydantic_object=Topic)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    # 사용자 쿼리에 답하십시오.\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],  # 입력 변수 설정\n",
    "    # 부분 변수에 형식 지시사항 설정\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser  # 체인을 구성합니다.\n",
    "\n",
    "chain.invoke({\"query\": query})  # 체인을 호출하여 쿼리 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10dcd4-2412-4761-9742-00ef7f9c7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OutputFixingParser\n",
    "# OutputFixingParser는 출력 파싱 과정에서 발생할 수 있는 오류를 자동으로 수정하는 기능을 제공합니다. \n",
    "# 이 파서는 기본적으로 다른 파서, 예를 들어 PydanticOutputParser 를 래핑하고, 이 파서가 처리할 수 없는 형식의 출력이나\n",
    "# 오류를 반환할 경우, 추가적인 LLM 호출을 통해 오류를 수정하도록 설계되었습니다.\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(\n",
    "        description=\"list of names of films they starred in\")\n",
    "\n",
    "\n",
    "actor_query = \"Generate the filmography for a random actor.\"\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "\n",
    "# 잘못된 형식을 일부러 입력\n",
    "misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\"\n",
    "\n",
    "# 잘못된 형식으로 입력된 데이터를 파싱하려고 시도\n",
    "parser.parse(misformatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f72cd22e-55a9-4ce5-97e8-9f0fea302dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(name='Tom Hanks', film_names=['Forrest Gump'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OutputFixingParser 를 사용하여 잘못된 형식을 바로 잡도록 하겠습니다.\n",
    "\n",
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI())\n",
    "\n",
    "# OutputFixingParser 를 사용하여 잘못된 형식의 출력을 파싱\n",
    "new_parser.parse(misformatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f172599-231e-4f67-b444-9cd3913e7a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

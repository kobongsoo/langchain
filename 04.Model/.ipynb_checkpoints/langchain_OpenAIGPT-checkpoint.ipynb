{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab08036-1d23-4868-8e41-a1fcc9b3c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출처 : https://wikidocs.net/233344\n",
    "# LangChain 설치 및 업데이트\n",
    "#!pip install -U langchain langchain-community langchain-experimental langchain-core langchain-openai langsmith langchainhub python-dotenv unstructured chromadb faiss-cpu rank_bm25 python-docx sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d917bbf-549e-4d3b-ad1d-4b32598de24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 루트경로에 .env 파일을 만들고, OPENAI_API_KEY='{API_KEY}' 식으로 입력한다.\n",
    "# API 키를 환경변수로 관리하기 위한 .env설정 파일 로딩\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # API 키 정보 로드\n",
    "print(f\"[API KEY]\\n{os.environ['OPENAI_API_KEY']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698bd4c0-abf9-4f58-857f-01f9cd7a9553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n",
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[답변]: 대한민국의 수도는 서울이야.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    ")\n",
    "\n",
    "# 질의내용\n",
    "question = \"대한민국의 수도는 뭐야?\"\n",
    "\n",
    "# 질의\n",
    "print(f\"[답변]: {llm.predict(question)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb8b49a1-2f1a-4064-bd2f-603e6c5c4b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['country'] template='{country}의 수도는 뭐야?'\n",
      "일본의 수도는 도쿄(Tokyo)입니다.\n",
      "[{'text': '호주의 수도는 캔버라입니다.'}, {'text': '중국의 수도는 베이징(北京)입니다.'}, {'text': '네덜란드의 수도는 암스테르담입니다.'}]\n",
      "generations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='호주의 수도는 캔버라입니다.', response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 17, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c2c16e41-f67e-46db-8c35-3c2f65ed7cd6-0'))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 19, 'total_tokens': 37}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e469d9d9-228d-46ec-ace4-a2250bea4e02-0'))], [ChatGeneration(text='네덜란드의 수도는 암스테르담입니다.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='네덜란드의 수도는 암스테르담입니다.', response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 22, 'total_tokens': 44}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-516f026f-edaf-479c-b1b7-a4e3b279c6b1-0'))]] llm_output={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 58, 'total_tokens': 111}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('c2c16e41-f67e-46db-8c35-3c2f65ed7cd6')), RunInfo(run_id=UUID('e469d9d9-228d-46ec-ace4-a2250bea4e02')), RunInfo(run_id=UUID('516f026f-edaf-479c-b1b7-a4e3b279c6b1'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# 질문 템플릿 형식 정의\n",
    "template = \"{country}의 수도는 뭐야?\"\n",
    "\n",
    "# 템플릿 완성\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "print(prompt)\n",
    "\n",
    "#LLMChain 객체\n",
    "#LLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 연결된 체인(Chain)객체 생성\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "# 체인 실행: run()\n",
    "print(llm_chain.run(country=\"일본\"))\n",
    "\n",
    "# apply() 함수로 여러개의 입력에 대한 처리를 한 번에 수행할 수 있습니다.\n",
    "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\": \"네덜란드\"}]\n",
    "print(llm_chain.apply(input_list))\n",
    "\n",
    "# generate() 는 문자열 대신에 LLMResult를 반환하는 점을 제외하고는 apply와 유사합니다.\n",
    "# 입력값\n",
    "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\": \"네덜란드\"}]\n",
    "# input_list 에 대한 결과 반환\n",
    "generated_result = llm_chain.generate(input_list)\n",
    "print(generated_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2182f6bc-c06a-4cd7-9eee-5eff307efacd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국은 동아시아에 위치한 고도로 발전한 선진국가로, 수도는 서울이며 인구는 약 5천만 명이 넘습니다. 대한민국은 민주공화국으로 정치체제를 갖추고 있으며, 대통령이 국가의 수장이며 국회의원들이 국가의 법을 제정하고 입법을 담당합니다.\n",
      "\n",
      "경제적으로는 세계에서 10대권에 속하는 경제력을 자랑하며, 선진국가로서 IT, 자동차, 조선, 화학 등 다양한 산업이 발달하고 있습니다. 또한 K-pop, K-drama 등 한류 문화가 세계적으로 큰 인기를 끌고 있습니다.\n",
      "\n",
      "대한민국은 역사적으로도 다양한 문화유산을 보유하고 있으며, 고려, 조선, 일제강점기, 한국전쟁 등 다양한 역사적 사건들을 겪어왔습니다. 또한 한반도 분단으로 인해 북한과의 관계가 중요한 이슈로 대두되고 있습니다.\n",
      "\n",
      "대한민국은 높은 교육수준과 체계적인 사회복지제도를 갖추고 있으며, 안전한 환경과 다양한 문화체험을 즐길 수 있는 나라로서 많은 이들이 방문하고 살고 있습니다. 현재는 코로나19로 인한 어려움을 겪고 있지만, 빠른 회복을 통해 더 나은 미래를 향해 나아가고 있습니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍\n",
    "# 스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.\n",
    "# 다음과 같이 streaming=True 로 설정하고 스트리밍으로 답변을 받기 위한 StreamingStdOutCallbackHandler() 을 콜백으로 지정합니다.\n",
    "\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# 객체 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,  # 창의성 (0.0 ~ 2.0)\n",
    "    max_tokens=2048,  # 최대 토큰수\n",
    "    model_name=\"gpt-3.5-turbo\",  # 모델명\n",
    "    streaming=True,\n",
    "    callbacks=[StreamingStdOutCallbackHandler()],\n",
    ")\n",
    "\n",
    "# 질의내용\n",
    "question = \"대한민국에 대해서 300자 내외로 최대한 상세히 알려줘\"\n",
    "\n",
    "# 스트리밍으로 답변 출력\n",
    "response = llm.predict(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff977561-74dd-4379-a6ba-bf48985704f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.71 ms, sys: 964 µs, total: 6.68 ms\n",
      "Wall time: 6.71 ms\n",
      "한국은 동아시아에 위치한 나라로, 서울이 수도이다. 전통적인 문화와 현대화가 공존하는 나라로, 한류와 K-pop 등의 문화가 전 세계적으로 인기를 얻고 있다. 경제는 선진국으로 발전하며 세계적으로 유명한 기업들이 많이 발달해 있으며, IT 산업이 발달하고 있다. 또한 한반도 분단 문제로 북한과의 관계가 계속되고 있으며, 국제사회에서 중요한 역할을 하고 있다. 한국은 맛있는 음식과 아름다운 자연 경꾼으로도 유명하며, 다양한 관광지와 문화유산이 많이 있다. 현대적인 도시와 전통적인 마을이 어우러진 다양한 매력을 가지고 있다.\n",
      "\n",
      "CPU times: user 5.24 ms, sys: 29 µs, total: 5.27 ms\n",
      "Wall time: 5.21 ms\n",
      "한국은 동아시아에 위치한 나라로, 서울이 수도이다. 전통적인 문화와 현대화가 공존하는 나라로, 한류와 K-pop 등의 문화가 전 세계적으로 인기를 얻고 있다. 경제는 선진국으로 발전하며 세계적으로 유명한 기업들이 많이 발달해 있으며, IT 산업이 발달하고 있다. 또한 한반도 분단 문제로 북한과의 관계가 계속되고 있으며, 국제사회에서 중요한 역할을 하고 있다. 한국은 맛있는 음식과 아름다운 자연 경꾼으로도 유명하며, 다양한 관광지와 문화유산이 많이 있다. 현대적인 도시와 전통적인 마을이 어우러진 다양한 매력을 가지고 있다.\n"
     ]
    }
   ],
   "source": [
    "# 캐싱(Caching)\n",
    "# LangChain은 LLM을 위한 선택적 캐싱 레이어를 제공합니다.\n",
    "# 이는 두 가지 이유로 유용합니다:\n",
    "# 동일한 완료를 여러 번 요청하는 경우 LLM 공급자에 대한 API 호출 횟수를 줄여 비용을 절감 할 수 있습니다.\n",
    "# LLM 제공업체에 대한 API 호출 횟수를 줄여 애플리케이션의 속도를 높일 수 있습니다.\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = PromptTemplate.from_template(\"{country} 에 대해서 200자 내외로 요약해줘\")\n",
    "\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "# 캐싱 설정\n",
    "set_llm_cache(SQLiteCache(database_path=\"my_llm_cache.db\"))\n",
    "\n",
    "%time response = chain.invoke({\"country\": \"한국\"})\n",
    "print(response.content)\n",
    "print()\n",
    "%time response = chain.invoke({\"country\": \"한국\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8def571-dfec-44de-b356-3fbefcfad5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='대한민국의 수도는 서울입니다.' response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 22, 'total_tokens': 37}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-8a6a7fb4-6270-4968-b948-f0f711be4aa5-0'\n",
      "content='대한민국의 수도는 서울입니다.' response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 22, 'total_tokens': 37}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-8a6a7fb4-6270-4968-b948-f0f711be4aa5-0'\n",
      "총 사용된 토큰수: \t\t0\n",
      "프롬프트에 사용된 토큰수: \t0\n",
      "답변에 사용된 토큰수: \t0\n",
      "호출에 청구된 금액(USD): \t$0.0\n"
     ]
    }
   ],
   "source": [
    "# 토큰 사용량 확인\n",
    "# 특정 호출에 대한 토큰 사용량을 추적하는 방법에 대해 설명합니다.\n",
    "# 이 기능은 현재 OpenAI API 에만 구현되어 있습니다.\n",
    "\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4\")\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke(\"대한민국의 수도는 어디야?\")\n",
    "    print(result)\n",
    "    result = llm.invoke(\"대한민국의 수도는 어디야?\")\n",
    "    print(result)\n",
    "    print(f\"총 사용된 토큰수: \\t\\t{cb.total_tokens}\")\n",
    "    print(f\"프롬프트에 사용된 토큰수: \\t{cb.prompt_tokens}\")\n",
    "    print(f\"답변에 사용된 토큰수: \\t{cb.completion_tokens}\")\n",
    "    print(f\"호출에 청구된 금액(USD): \\t${cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19626df8-5f25-43e3-b99b-eb1ff819c156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatOpenAI: True\n",
      "*is_lc_serializable: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/MOCOMSYS/anaconda3/envs/bong/lib/python3.9/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `load` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='사과의 색상은 주로 빨간색이지만, 녹색, 노란색, 주황색 등 다양한 색상의 사과도 있습니다.' response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 24, 'total_tokens': 75}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-95feba27-0677-4521-8cb3-7396803d581e-0'\n"
     ]
    }
   ],
   "source": [
    "# 모델 직렬화로 저장 하고 불러오기\n",
    "# LangChain 은 직렬화(Serialization) 체계를 공유합니다.\n",
    "# is_lc_serializable 클래스 메서드로 실행하여 LangChain 클래스가 직렬화 가능한지 확인할 수 있습니다.\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "# 직렬화가 가능한지 체크합니다.\n",
    "print(f\"ChatOpenAI: {ChatOpenAI.is_lc_serializable()}\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "prompt = PromptTemplate.from_template(\"{fruit}의 색상이 무엇입니까?\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "print(f'*is_lc_serializable: {chain.is_lc_serializable()}')\n",
    "\n",
    "# 모델 저장\n",
    "from langchain.load import dumpd\n",
    "import pickle\n",
    "dumped_chain = dumpd(chain)\n",
    "# fuit_chain.pkl 파일로 직렬화된 체인을 저장합니다.\n",
    "with open(\"fruit_chain.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dumped_chain, f)\n",
    "    \n",
    "# load: 저장한 모델 불러오기\n",
    "with open(\"fruit_chain.pkl\", \"rb\") as f:\n",
    "    loaded_chain = pickle.load(f)\n",
    "    \n",
    "from langchain.load.load import load\n",
    "loaded_chain = load(loaded_chain)\n",
    "print(loaded_chain.invoke({\"fruit\": \"사과\"}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
